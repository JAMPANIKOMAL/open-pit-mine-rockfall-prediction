{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14d87b5",
   "metadata": {},
   "source": [
    "# Notebook 3: Preprocessing & Modeling\n",
    "\n",
    "## 1. Objective\n",
    "\n",
    "This notebook marks the transition from analysis (EDA) to prediction (Machine Learning).\n",
    "\n",
    "Our work in Notebooks 1 and 2 was crucial. We now have:\n",
    "1.  A clean, high-quality dataset: `rockfall_synthetic_data.csv`.\n",
    "2.  A deep understanding of our data, including its \"imbalanced\" nature and strongest predictors.\n",
    "\n",
    "The purpose of *this* notebook is to use that knowledge to build and select the best possible machine learning model. Our plan is based on our EDA findings:\n",
    "\n",
    "1.  **Preprocessing:** We will prepare the data for modeling using standard technologies. This includes a `StandardScaler` (because our features have different scales) and an `LabelEncoder` (to convert our text target \"Low\", \"Critical\" into numbers 0, 3).\n",
    "2.  **Handling Imbalance:** Our biggest challenge (found in Notebook 2) is that \"Critical\" events are rare (1.7%). We will use the `class_weight='balanced'` parameter in our models. This advanced technique forces the model to pay extra attention to the rare classes, preventing it from just ignoring them.\n",
    "3.  **Model Training:** We will train a \"ladder\" of models, from a simple baseline (`LogisticRegression`) to a powerful, modern standard (`XGBClassifier`).\n",
    "4.  **Model Evaluation:** We will *not* use \"Accuracy\" as our success metric. We will use a **Classification Report**. Our primary goal is to find the model with the highest **Recall** on the \"Critical\" class, as this is the most important prediction to get right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06899705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'rockfall_synthetic_data.csv'.\n",
      "Dataset has 20000 rows and 6 columns.\n",
      "\n",
      "--- Data Head (First 5 Rows) ---\n",
      "   rainfall_mm_past_24h  seismic_activity  joint_water_pressure_kPa  \\\n",
      "0             16.351962          1.042005                 41.542877   \n",
      "1              4.133069          1.410756                 34.360071   \n",
      "2              7.764729          1.554489                 38.339998   \n",
      "3             14.857486          1.517141                 50.282894   \n",
      "4              0.000000          0.941456                 31.325325   \n",
      "\n",
      "   vibration_level  displacement_mm risk_level  \n",
      "0         0.206142         6.991127        Low  \n",
      "1         0.349532         8.686621        Low  \n",
      "2         0.384975        10.007807        Low  \n",
      "3         0.351243        13.029807     Medium  \n",
      "4         0.266100         8.382537        Low  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# --- 1. Preprocessing Tools ---\n",
    "# train_test_split: To split our data into a 'training' set and a 'testing' set.\n",
    "# StandardScaler: To rescale all our number features so they have a similar scale.\n",
    "# LabelEncoder: To turn our text target ('Low', 'High') into numbers (0, 3).\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# --- 2. Model Algorithms ---\n",
    "# These are the different models we will train and compare.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- 3. Evaluation Tools ---\n",
    "# classification_report: Our main tool. It shows Precision, Recall, and F1-score.\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- 4. Define File Paths ---\n",
    "BASE_DIR = '..'\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "DATA_FILE = os.path.join(DATA_DIR, 'rockfall_synthetic_data.csv')\n",
    "\n",
    "# This is where we will save our trained models\n",
    "MODELS_DIR = os.path.join(BASE_DIR, 'models')\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- 5. Load the Data ---\n",
    "try:\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    print(f\"Successfully loaded '{os.path.basename(DATA_FILE)}'.\")\n",
    "    print(f\"Dataset has {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"--- ERROR ---\")\n",
    "    print(f\"The file '{os.path.basename(DATA_FILE)}' was not found at: {DATA_FILE}\")\n",
    "    print(\"Please make sure Notebook 1 was run successfully and the file was saved.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# --- 6. Initial Data Inspection ---\n",
    "if 'df' in locals():\n",
    "    print(\"\\n--- Data Head (First 5 Rows) ---\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "998d8413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (features) shape: (20000, 5)\n",
      "y (target) shape: (20000,)\n",
      "\n",
      "--- Target Variable Encoding ---\n",
      "Text labels: ['Critical' 'High' 'Low' 'Medium']\n",
      "Encoded numbers: [0 1 2 3]\n",
      "Mapping: {0: 'Critical', 1: 'High', 2: 'Low', 3: 'Medium'}\n",
      "\n",
      "--- Data Splitting ---\n",
      "X_train shape: (16000, 5)\n",
      "X_test shape: (4000, 5)\n",
      "y_train shape: (16000,)\n",
      "y_test shape: (4000,)\n",
      "\n",
      "--- Feature Scaling ---\n",
      "Features have been scaled using StandardScaler.\n",
      "X_train_scaled mean (should be ~0): -0.00\n",
      "X_test_scaled mean (should be similar): 0.01\n",
      "\n",
      "--- Preprocessing Complete ---\n",
      "LabelEncoder saved to ..\\models\\label_encoder.pkl\n",
      "StandardScaler saved to ..\\models\\scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# ### 2.1. Define Features (X) and Target (y)\n",
    "# ---\n",
    "\n",
    "# 'X' (features) is our 5 numerical columns.\n",
    "X = df.drop('risk_level', axis=1)\n",
    "\n",
    "# 'y' (target) is the one column we are trying to predict.\n",
    "y = df['risk_level']\n",
    "\n",
    "print(f\"X (features) shape: {X.shape}\")\n",
    "print(f\"y (target) shape: {y.shape}\")\n",
    "\n",
    "\n",
    "# ---\n",
    "# ### 2.2. Encode the Target Variable (y)\n",
    "# ---\n",
    "# We need to convert the text labels ('Low', 'Medium', 'High', 'Critical')\n",
    "# into numbers (0, 1, 2, 3) so the models can understand them.\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Let's see what the new classes are:\n",
    "# We also save the logical order for our final reports\n",
    "# We use .tolist() to save it as a simple list\n",
    "target_names = le.classes_.tolist()\n",
    "target_map = {index: label for index, label in enumerate(target_names)}\n",
    "\n",
    "print(\"\\n--- Target Variable Encoding ---\")\n",
    "print(f\"Text labels: {le.classes_}\")\n",
    "print(f\"Encoded numbers: {le.transform(le.classes_)}\")\n",
    "print(f\"Mapping: {target_map}\")\n",
    "\n",
    "\n",
    "# ---\n",
    "# ### 2.3. Split Data into Training and Testing Sets\n",
    "# ---\n",
    "# This is a critical step. We will train our model on 80% of the data\n",
    "# and test it on 20% of \"unseen\" data.\n",
    "# 'stratify=y_encoded' is crucial for our imbalanced dataset.\n",
    "# It ensures that our 'Critical' samples (1.7%) are split 80/20\n",
    "# and don't all end up in just one set.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y_encoded, \n",
    "    test_size=0.2,    # 20% of data for testing\n",
    "    random_state=42,  # Ensures our split is reproducible\n",
    "    stratify=y_encoded # CRITICAL for imbalanced data\n",
    ")\n",
    "\n",
    "print(\"\\n--- Data Splitting ---\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "# ---\n",
    "# ### 2.4. Scale the Numerical Features (X)\n",
    "# ---\n",
    "# Our features have different scales (e.g., rainfall 0-22 vs. vibration 0-1.5).\n",
    "# StandardScaler rescales them all to have a mean of 0 and std of 1.\n",
    "# We 'fit' the scaler ONLY on the training data to prevent data leakage.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n--- Feature Scaling ---\")\n",
    "print(\"Features have been scaled using StandardScaler.\")\n",
    "print(f\"X_train_scaled mean (should be ~0): {X_train_scaled.mean():.2f}\")\n",
    "print(f\"X_test_scaled mean (should be similar): {X_test_scaled.mean():.2f}\")\n",
    "\n",
    "\n",
    "# ---\n",
    "# ### 2.5. Save Preprocessing Objects\n",
    "# ---\n",
    "# We must save the 'LabelEncoder' (le) and 'StandardScaler' (scaler)\n",
    "# so our final web app (app.py) can use the exact same transformations.\n",
    "\n",
    "le_path = os.path.join(MODELS_DIR, 'label_encoder.pkl')\n",
    "scaler_path = os.path.join(MODELS_DIR, 'scaler.pkl')\n",
    "\n",
    "with open(le_path, 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "    \n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"\\n--- Preprocessing Complete ---\")\n",
    "print(f\"LabelEncoder saved to {le_path}\")\n",
    "print(f\"StandardScaler saved to {scaler_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428e51d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function 'evaluate_model' is defined and ready to use.\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# ### 3.1. Create a Model \"Evaluation\" Function\n",
    "# ---\n",
    "#\n",
    "# We will be training 4 different models. To compare them fairly,\n",
    "# we need to do the exact same evaluation for each one.\n",
    "#\n",
    "# A \"helper function\" is the best way to do this. This function will:\n",
    "# 1. Take a trained model as input.\n",
    "# 2. Make predictions on our \"unseen\" test data (X_test_scaled).\n",
    "# 3. Print a full Classification Report (our main success metric).\n",
    "\n",
    "def evaluate_model(model, model_name):\n",
    "    \"\"\"\n",
    "    Takes a trained model and a name, makes predictions on the\n",
    "    test set, and prints a classification report.\n",
    "    \"\"\"\n",
    "    print(f\"--- Evaluating: {model_name} ---\")\n",
    "    \n",
    "    # 1. Make predictions on the test data\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # 2. Print the classification report\n",
    "    # We use our 'target_names' list from Cell 3 to get the text labels\n",
    "    report = classification_report(\n",
    "        y_test, \n",
    "        y_pred, \n",
    "        target_names=target_names\n",
    "    )\n",
    "    print(report)\n",
    "\n",
    "# ---\n",
    "# This cell just defines the function. \n",
    "# No output will be shown, but the function is now in memory.\n",
    "# ---\n",
    "print(\"Helper function 'evaluate_model' is defined and ready to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c82197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Model 1: Logistic Regression ---\n",
      "Model training complete.\n",
      "--- Evaluating: Logistic Regression ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.62      0.87      0.72        69\n",
      "        High       0.71      0.83      0.77       290\n",
      "         Low       0.99      0.98      0.99      2019\n",
      "      Medium       0.97      0.93      0.95      1622\n",
      "\n",
      "    accuracy                           0.95      4000\n",
      "   macro avg       0.82      0.90      0.86      4000\n",
      "weighted avg       0.96      0.95      0.95      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# ### 3.2. Model 1: Logistic Regression (Baseline)\n",
    "# ---\n",
    "#\n",
    "# We will start with a simple, fast model called Logistic Regression.\n",
    "# This will be our \"baseline\". A good, complex model (like XGBoost)\n",
    "# should be able to easily beat this score.\n",
    "\n",
    "print(\"--- Training Model 1: Logistic Regression ---\")\n",
    "\n",
    "# 1. Initialize the model\n",
    "# We set 'class_weight=\"balanced\"' to handle our imbalanced dataset.\n",
    "# This tells the model to \"pay more attention\" to the rare 'Critical' class.\n",
    "# We set 'max_iter=1000' to give it more time to find a good solution.\n",
    "log_reg = LogisticRegression(\n",
    "    class_weight='balanced', \n",
    "    max_iter=1000, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Train the model\n",
    "# We 'fit' the model on our scaled training data\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# 3. Evaluate the model\n",
    "# We use our helper function from Cell 4\n",
    "evaluate_model(log_reg, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b285e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Model 2: K-Nearest Neighbors ---\n",
      "Model training complete.\n",
      "--- Evaluating: K-Nearest Neighbors (k=7) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.86      0.80      0.83        69\n",
      "        High       0.91      0.88      0.89       290\n",
      "         Low       0.98      0.98      0.98      2019\n",
      "      Medium       0.95      0.97      0.96      1622\n",
      "\n",
      "    accuracy                           0.96      4000\n",
      "   macro avg       0.92      0.90      0.91      4000\n",
      "weighted avg       0.96      0.96      0.96      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# ### 3.3. Model 2: K-Nearest Neighbors (KNN)\n",
    "# ---\n",
    "#\n",
    "# KNN is a simple but powerful model. It works by \"polling\" the\n",
    "# \"k\" (e.g., 5) closest data points from the training set.\n",
    "#\n",
    "# NOTE: This model does *not* have a 'class_weight' parameter.\n",
    "# It will be interesting to see how it handles our imbalanced data\n",
    "# without that special instruction.\n",
    "\n",
    "print(\"--- Training Model 2: K-Nearest Neighbors ---\")\n",
    "\n",
    "# 1. Initialize the model\n",
    "# 'n_neighbors=7' is a common starting point. We could\n",
    "# \"tune\" this number later, but 7 is a solid choice.\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# 2. Train the model\n",
    "# We 'fit' the model on our scaled training data\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# 3. Evaluate the model\n",
    "evaluate_model(knn, \"K-Nearest Neighbors (k=7)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52dfaf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Model 3: Random Forest Classifier ---\n",
      "Model training complete.\n",
      "--- Evaluating: Random Forest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       1.00      1.00      1.00        69\n",
      "        High       1.00      1.00      1.00       290\n",
      "         Low       1.00      1.00      1.00      2019\n",
      "      Medium       1.00      1.00      1.00      1622\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# ### 3.4. Model 3: Random Forest Classifier\n",
    "# ---\n",
    "#\n",
    "# This is our first \"ensemble\" model. It's much more powerful\n",
    "# and smarter than our first two models. It builds hundreds of\n",
    "# \"decision trees\" and combines their votes.\n",
    "\n",
    "print(\"--- Training Model 3: Random Forest Classifier ---\")\n",
    "\n",
    "# 1. Initialize the model\n",
    "# We again set 'class_weight=\"balanced\"' to handle our imbalanced data.\n",
    "# 'n_estimators=100' means it will build 100 decision trees.\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    class_weight='balanced', \n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Uses all available CPU cores to speed up training\n",
    ")\n",
    "\n",
    "# 2. Train the model\n",
    "# This may take a few seconds, as it's a more complex model.\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# 3. Evaluate the model\n",
    "evaluate_model(rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03c2ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Model 4: XGBClassifier ---\n",
      "Model training complete.\n",
      "--- Evaluating: XGBClassifier ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.97      0.99      0.98        69\n",
      "        High       0.99      0.98      0.98       290\n",
      "         Low       1.00      1.00      1.00      2019\n",
      "      Medium       1.00      1.00      1.00      1622\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       0.99      0.99      0.99      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# ### 3.5. Model 4: XGBClassifier (Advanced)\n",
    "# ---\n",
    "#\n",
    "# This is our most advanced model. XGBoost (eXtreme Gradient Boosting)\n",
    "# is the \"industry standard\" for tabular data and wins many Kaggle competitions.\n",
    "#\n",
    "# Like Random Forest, it's an \"ensemble\", but it builds trees \n",
    "# sequentially, with each new tree learning from the \"mistakes\" of the last one.\n",
    "\n",
    "print(\"--- Training Model 4: XGBClassifier ---\")\n",
    "\n",
    "# 1. Initialize the model\n",
    "# NOTE: XGBoost's 'class_weight' parameter is different.\n",
    "# The best way to handle imbalance here is to set 'scale_pos_weight'\n",
    "# for each class, but for a simple comparison, we will first try\n",
    "# it without special handling and see how it performs.\n",
    "#\n",
    "# We also need to tell it to use the 'multi:softmax' objective\n",
    "# because we have more than 2 classes.\n",
    "xgb = XGBClassifier(\n",
    "    objective='multi:softmax',  # Use 'multi:softmax' for multi-class problems\n",
    "    num_class=4,                # We have 4 classes\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2. Train the model\n",
    "# This may also take a few seconds.\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# 3. Evaluate the model\n",
    "evaluate_model(xgb, \"XGBClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e623695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model 'Tournament' Results ---\n",
      "Based on 'Critical' class Recall (our most important metric):\n",
      "\n",
      "1. Logistic Regression: 87%\n",
      "2. K-Nearest Neighbors: 80%\n",
      "3. Random Forest:         100% (Potential Overfitting)\n",
      "4. XGBClassifier:         99% (Highly Robust)\n",
      "\n",
      "--- Analysis ---\n",
      "The 100% score for Random Forest is a strong sign of overfitting.\n",
      "It has likely 'memorized' the exact rules of our synthetic data.\n",
      "The 99% score for XGBClassifier is more realistic and likely to be more\n",
      "robust on new, unseen ('messy') data.\n",
      "\n",
      "--- NEW PLAN ---\n",
      "We will save BOTH top models for a final head-to-head comparison\n",
      "in Notebook 4: Model Interpretation.\n",
      "\n",
      "--- SUCCESS! ---\n",
      "Random Forest model saved to: ..\\models\\rf_model.pkl\n",
      "XGBoost model saved to: ..\\models\\xgb_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# ### 4.1. Model Comparison & Analysis\n",
    "# ---\n",
    "\n",
    "print(\"--- Model 'Tournament' Results ---\")\n",
    "print(\"Based on 'Critical' class Recall (our most important metric):\\n\")\n",
    "print(\"1. Logistic Regression: 87%\")\n",
    "print(\"2. K-Nearest Neighbors: 80%\")\n",
    "print(\"3. Random Forest:         100% (Potential Overfitting)\")\n",
    "print(\"4. XGBClassifier:         99% (Highly Robust)\")\n",
    "\n",
    "print(\"\\n--- Analysis ---\")\n",
    "print(\"The 100% score for Random Forest is a strong sign of overfitting.\")\n",
    "print(\"It has likely 'memorized' the exact rules of our synthetic data.\")\n",
    "print(\"The 99% score for XGBClassifier is more realistic and likely to be more\")\n",
    "print(\"robust on new, unseen ('messy') data.\")\n",
    "\n",
    "print(\"\\n--- NEW PLAN ---\")\n",
    "print(\"We will save BOTH top models for a final head-to-head comparison\")\n",
    "print(\"in Notebook 4: Model Interpretation.\")\n",
    "\n",
    "\n",
    "# ---\n",
    "# ### 4.2. Save Both Top Models\n",
    "# ---\n",
    "\n",
    "# 'rf' is the variable holding our Random Forest model from Cell 7\n",
    "# 'xgb' is the variable holding our XGBoost model from Cell 8\n",
    "rf_model_path = os.path.join(MODELS_DIR, 'rf_model.pkl')\n",
    "xgb_model_path = os.path.join(MODELS_DIR, 'xgb_model.pkl')\n",
    "\n",
    "try:\n",
    "    # Save Random Forest\n",
    "    with open(rf_model_path, 'wb') as f:\n",
    "        pickle.dump(rf, f)\n",
    "    \n",
    "    # Save XGBoost\n",
    "    with open(xgb_model_path, 'wb') as f:\n",
    "        pickle.dump(xgb, f)\n",
    "    \n",
    "    print(\"\\n--- SUCCESS! ---\")\n",
    "    print(f\"Random Forest model saved to: {rf_model_path}\")\n",
    "    print(f\"XGBoost model saved to: {xgb_model_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"--- ERROR ---\")\n",
    "    print(f\"An error occurred while saving the models: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rockfall-venv)",
   "language": "python",
   "name": "rockfall-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
