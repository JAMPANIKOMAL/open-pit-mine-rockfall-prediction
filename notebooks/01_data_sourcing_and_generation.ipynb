{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a80c973",
   "metadata": {},
   "source": [
    "# Notebook 1: Data Sourcing & High-Fidelity Generation\n",
    "\n",
    "## 1. Objective\n",
    "\n",
    "The foundation of any analytics project is its data. A significant challenge in mining analytics is the lack of public, high-quality data, as real-world geotechnical sensor data is proprietary.\n",
    "\n",
    "To overcome this, this notebook creates a **high-fidelity synthetic dataset**. We will follow a professional workflow:\n",
    "\n",
    "1.  **Sourcing:** We will load and analyze two real-world Kaggle datasets (one for rainfall, one for seismic activity) to understand their statistical properties.\n",
    "2.  **Generation:** We will use these real-world properties as our \"recipe\" to build a new, clean dataset of 20,000 samples.\n",
    "3.  **Logic:** We will engineer purposeful, complex relationships between the features to create a rich dataset for analysis.\n",
    "\n",
    "This notebook's final output is the `rockfall_synthetic_data.csv` file, which will be the foundation for the entire project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c302d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b1ca8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ebf81a4",
   "metadata": {},
   "source": [
    "## 2. Part A: Sourcing & Analyzing \"Driver\" Datasets\n",
    "\n",
    "To build a realistic synthetic dataset, we must first understand the properties of real-world \"driver\" factors. We will load and analyze two datasets from Kaggle to create our \"recipe\".\n",
    "\n",
    "**Datasets Used:**\n",
    "1.  **Rainfall:** \"Rainfall Dataset for Simple Time Series Analysis\"\n",
    "2.  **Seismic:** \"All the Earthquakes Dataset : from 1990-2023\"\n",
    "\n",
    "We will analyze their statistical distributions to ensure our synthetic data is not just random, but is statistically representative of real-world patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffecaebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory set to: ..\\data\n",
      "Rainfall data ('rainfall.csv') already exists. Skipping download.\n",
      "Seismic data ('earthquake_data.csv') already exists. Skipping download.\n",
      "\n",
      "--- Data Sourcing and Setup Complete ---\n",
      "We are ready to analyze:\n",
      "1. rainfall.csv\n",
      "2. earthquake_data.csv\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "# ---\n",
    "# ### 2.1. Setup File Paths & Download Data\n",
    "# ---\n",
    "\n",
    "# This is the path to our main project directory (one level up from 'notebooks')\n",
    "BASE_DIR = '..'\n",
    "\n",
    "# --- Define Data Directories ---\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "os.makedirs(DATA_DIR, exist_ok=True) # Create 'data' folder if it doesn't exist\n",
    "print(f\"Data directory set to: {DATA_DIR}\")\n",
    "\n",
    "\n",
    "# --- Define Kaggle Dataset \"Slugs\" (from their URL) ---\n",
    "RAINFALL_SLUG = 'sujithmandala/rainfall-dataset-for-simple-time-series-analysis'\n",
    "SEISMIC_SLUG = 'alessandrolobello/the-ultimate-earthquake-dataset-from-1990-2023'\n",
    "\n",
    "# --- Define our Standard File Names ---\n",
    "RAINFALL_DRIVER_FILE = os.path.join(DATA_DIR, 'rainfall.csv')\n",
    "SEISMIC_DRIVER_FILE = os.path.join(DATA_DIR, 'earthquake_data.csv')\n",
    "SYNTHETIC_DATA_FILE = os.path.join(DATA_DIR, 'rockfall_synthetic_data.csv')\n",
    "\n",
    "# --- Define the *actual* downloaded name for the seismic file ---\n",
    "# We found this name from your \"debug\" cell output.\n",
    "DOWNLOADED_SEISMIC_NAME = os.path.join(DATA_DIR, 'Eartquakes-1990-2023.csv')\n",
    "\n",
    "\n",
    "# --- Download Logic ---\n",
    "# This code will check if the file already exists. If not, it will download it.\n",
    "\n",
    "# 1. Download Rainfall Data\n",
    "if not os.path.exists(RAINFALL_DRIVER_FILE):\n",
    "    print(f\"Downloading {RAINFALL_SLUG}...\")\n",
    "    try:\n",
    "        kaggle.api.dataset_download_files(RAINFALL_SLUG, path=DATA_DIR, unzip=True)\n",
    "        print(f\"Rainfall data downloaded and unzipped to {DATA_DIR}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading rainfall data: {e}\")\n",
    "        print(\"Please check your Kaggle API setup (kaggle.json).\")\n",
    "else:\n",
    "    print(f\"Rainfall data ('{os.path.basename(RAINFALL_DRIVER_FILE)}') already exists. Skipping download.\")\n",
    "\n",
    "# 2. Download and Rename Seismic Data\n",
    "if not os.path.exists(SEISMIC_DRIVER_FILE):\n",
    "    print(f\"Checking for seismic data...\")\n",
    "    \n",
    "    # Check if the *original downloaded file* exists (e.g., Eartquakes-1990-2023.csv)\n",
    "    if os.path.exists(DOWNLOADED_SEISMIC_NAME):\n",
    "        print(f\"Found '{os.path.basename(DOWNLOADED_SEISMIC_NAME)}'. Renaming...\")\n",
    "        os.rename(DOWNLOADED_SEISMIC_NAME, SEISMIC_DRIVER_FILE)\n",
    "        print(f\"Successfully renamed to '{os.path.basename(SEISMIC_DRIVER_FILE)}'.\")\n",
    "    \n",
    "    # If neither file exists, then we need to download it\n",
    "    else:\n",
    "        print(f\"Downloading {SEISMIC_SLUG}...\")\n",
    "        try:\n",
    "            kaggle.api.dataset_download_files(SEISMIC_SLUG, path=DATA_DIR, unzip=True)\n",
    "            print(\"Seismic data downloaded and unzipped.\")\n",
    "            \n",
    "            # Give the system a second to make sure the file is written\n",
    "            time.sleep(2) \n",
    "            \n",
    "            # Now, do the rename\n",
    "            if os.path.exists(DOWNLOADED_SEISMIC_NAME):\n",
    "                os.rename(DOWNLOADED_SEISMIC_NAME, SEISMIC_DRIVER_FILE)\n",
    "                print(f\"Successfully renamed '{os.path.basename(DOWNLOADED_SEISMIC_NAME)}' to '{os.path.basename(SEISMIC_DRIVER_FILE)}'.\")\n",
    "            else:\n",
    "                print(f\"Warning: Downloaded seismic data, but the file '{os.path.basename(DOWNLOADED_SEISMIC_NAME)}' was not found for renaming.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading seismic data: {e}\")\n",
    "            print(\"Please check your Kaggle API setup (kaggle.json).\")\n",
    "else:\n",
    "    print(f\"Seismic data ('{os.path.basename(SEISMIC_DRIVER_FILE)}') already exists. Skipping download.\")\n",
    "    \n",
    "print(\"\\n--- Data Sourcing and Setup Complete ---\")\n",
    "print(f\"We are ready to analyze:\")\n",
    "print(f\"1. {os.path.basename(RAINFALL_DRIVER_FILE)}\")\n",
    "print(f\"2. {os.path.basename(SEISMIC_DRIVER_FILE)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rockfall-venv)",
   "language": "python",
   "name": "rockfall-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
